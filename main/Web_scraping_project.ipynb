{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "GLer4g6iTO_V",
        "GYztMbClBkzz",
        "BvsXlsTn_KNL"
      ],
      "authorship_tag": "ABX9TyMPvKRo2lrCKQ9vfbWgmXkr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Unseen-Elder/Web_Scraping_of_Github_Topics/blob/main/main/Web_scraping_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scraping Top Repositories for Topics on GitHub\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yZ11RIJwcOAN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Web Scraping : \n",
        "- Web scraping is the process of automatically collecting information from websites. It involves using software or programming tools to extract data from web pages, which can then be analyzed, stored, or used in other applications.\n",
        "\n",
        "- Web scraping can be used for a variety of purposes, such as market research, price monitoring, content aggregation, and more. However, it's important to note that not all websites allow web scraping, and some may require permission or have legal restrictions on the use of their data.\n",
        "\n",
        "GitHub : \n",
        "- GitHub is like a virtual filing cabinet where programmers can store and manage their code. It provides a centralized location for developers to collaborate on code, share their work with others, and track changes made by different contributors. GitHub also offers tools for managing issues, tracking bugs, and organizing code repositories.\n",
        "\n",
        "- GitHub is widely used in the software development community, and it's an essential tool for open source projects. It allows developers to work together on projects, contribute code to other projects, and collaborate with others around the world. Additionally, GitHub provides a platform for code hosting, which means that anyone can access and download code for free, making it a valuable resource for learning and education.\n",
        "\n",
        "\n",
        "\n",
        "Tools we will be using are : \n",
        "- **Python**\n",
        "- **Selenium**\n",
        "- **BeautifulSoup** \n",
        "- **Pandas**\n",
        "\n"
      ],
      "metadata": {
        "id": "neTWhnWv1feB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Here are the steps we'll follow:\n",
        "\n",
        "- We're going to scrape https://github.com/topics\n",
        "- We'll get a list of topics. For each topic, we'll get topic title, topic page URL and topic description\n",
        "- For each topic, we'll get the top 40  repositories in the topic from the topic page\n",
        "- For each repository, we'll grab the repo name, username, stars and repo URL\n",
        "- For each topic we'll create a CSV file in the following format:\n",
        "\n",
        "| Repo Name | Username | Stars | Repo URL                            |\n",
        "|-----------|----------|-------|-------------------------------------|\n",
        "| three.js  | mrdoob   | 69.7k | https://github.com/mrdoob/three.js  |\n",
        "| libgdx    | libgdx   | 18.3k | https://github.com/libgdx/libgdx    |\n",
        "\n"
      ],
      "metadata": {
        "id": "5ECUSKN6caxb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.Downloading important libraries like Selenium and BeautifulSoup"
      ],
      "metadata": {
        "id": "L-kD64tQHm_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# Ubuntu no longer distributes chromium-browser outside of snap\n",
        "# Proposed solution: https://askubuntu.com/questions/1204571/how-to-install-chromium-without-snap\n",
        "\n",
        "# Add debian buster\n",
        "cat > /etc/apt/sources.list.d/debian.list <<'EOF'\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster.gpg] http://deb.debian.org/debian buster main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster-updates.gpg] http://deb.debian.org/debian buster-updates main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-security-buster.gpg] http://deb.debian.org/debian-security buster/updates main\n",
        "EOF\n",
        "\n",
        "# Add keys\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys DCC9EFBF77E11517\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 648ACFD622F3D138\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 112695A0E562B32A\n",
        "\n",
        "apt-key export 77E11517 | gpg --dearmour -o /usr/share/keyrings/debian-buster.gpg\n",
        "apt-key export 22F3D138 | gpg --dearmour -o /usr/share/keyrings/debian-buster-updates.gpg\n",
        "apt-key export E562B32A | gpg --dearmour -o /usr/share/keyrings/debian-security-buster.gpg\n",
        "\n",
        "# Prefer debian repo for chromium* packages only\n",
        "# Note the double-blank lines between entries\n",
        "cat > /etc/apt/preferences.d/chromium.pref << 'EOF'\n",
        "Package: *\n",
        "Pin: release a=eoan\n",
        "Pin-Priority: 500\n",
        "\n",
        "\n",
        "Package: *\n",
        "Pin: origin \"deb.debian.org\"\n",
        "Pin-Priority: 300\n",
        "\n",
        "\n",
        "Package: chromium*\n",
        "Pin: origin \"deb.debian.org\"\n",
        "Pin-Priority: 700\n",
        "EOF\n",
        "\n",
        "# Install chromium and chromium-driver\n",
        "apt-get update\n",
        "apt-get install -y chromium-browser --quiet\n",
        "apt-get install chromium chromium-driver --quiet\n",
        "\n",
        "# Install selenium\n",
        "pip install selenium --quiet\n",
        "\n",
        "# Install Beautifulsoup\n",
        "pip install beautifulsoup4 --quiet"
      ],
      "metadata": {
        "id": "Uw2fha7hMAJa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cdf6df3-3298-470a-a338-555579d0252b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Executing: /tmp/apt-key-gpghome.d6yB2qBIKw/gpg.1.sh --keyserver keyserver.ubuntu.com --recv-keys DCC9EFBF77E11517\n",
            "gpg: key DCC9EFBF77E11517: public key \"Debian Stable Release Key (10/buster) <debian-release@lists.debian.org>\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Executing: /tmp/apt-key-gpghome.oHlBxTHVOg/gpg.1.sh --keyserver keyserver.ubuntu.com --recv-keys 648ACFD622F3D138\n",
            "gpg: key DC30D7C23CBBABEE: public key \"Debian Archive Automatic Signing Key (10/buster) <ftpmaster@debian.org>\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Executing: /tmp/apt-key-gpghome.0HE6kIcLu3/gpg.1.sh --keyserver keyserver.ubuntu.com --recv-keys 112695A0E562B32A\n",
            "gpg: key 4DFAB270CAA96DFA: public key \"Debian Security Archive Automatic Signing Key (10/buster) <ftpmaster@debian.org>\" imported\n",
            "gpg: Total number processed: 1\n",
            "gpg:               imported: 1\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "Warning: apt-key output should not be parsed (stdout is not a terminal)\n",
            "Get:1 http://deb.debian.org/debian buster InRelease [122 kB]\n",
            "Get:2 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Get:3 http://deb.debian.org/debian buster-updates InRelease [56.6 kB]\n",
            "Get:4 http://deb.debian.org/debian-security buster/updates InRelease [34.8 kB]\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Get:6 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease [18.1 kB]\n",
            "Get:9 http://deb.debian.org/debian buster/main amd64 Packages [10.7 MB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Get:13 http://deb.debian.org/debian buster-updates/main amd64 Packages [9,745 B]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Get:15 http://deb.debian.org/debian-security buster/updates/main amd64 Packages [600 kB]\n",
            "Hit:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:17 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:18 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,545 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main Sources [2,403 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,026 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main amd64 Packages [1,138 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [28.6 kB]\n",
            "Fetched 21.1 MB in 4s (4,818 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following additional packages will be installed:\n",
            "  apparmor liblzo2-2 snapd squashfs-tools\n",
            "Suggested packages:\n",
            "  apparmor-profiles-extra apparmor-utils\n",
            "The following NEW packages will be installed:\n",
            "  apparmor chromium-browser liblzo2-2 snapd squashfs-tools\n",
            "0 upgraded, 5 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 38.6 MB of archives.\n",
            "After this operation, 174 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 apparmor amd64 2.13.3-7ubuntu5.1 [494 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/main amd64 liblzo2-2 amd64 2.10-2 [50.8 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 squashfs-tools amd64 1:4.4-1ubuntu0.3 [117 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 snapd amd64 2.58+20.04 [37.9 MB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 chromium-browser amd64 1:85.0.4183.83-0ubuntu0.20.04.3 [48.5 kB]\n",
            "Fetched 38.6 MB in 1s (36.5 MB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package apparmor.\n",
            "(Reading database ... 128285 files and directories currently installed.)\n",
            "Preparing to unpack .../apparmor_2.13.3-7ubuntu5.1_amd64.deb ...\n",
            "Unpacking apparmor (2.13.3-7ubuntu5.1) ...\n",
            "Selecting previously unselected package liblzo2-2:amd64.\n",
            "Preparing to unpack .../liblzo2-2_2.10-2_amd64.deb ...\n",
            "Unpacking liblzo2-2:amd64 (2.10-2) ...\n",
            "Selecting previously unselected package squashfs-tools.\n",
            "Preparing to unpack .../squashfs-tools_1%3a4.4-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking squashfs-tools (1:4.4-1ubuntu0.3) ...\n",
            "Selecting previously unselected package snapd.\n",
            "Preparing to unpack .../snapd_2.58+20.04_amd64.deb ...\n",
            "Unpacking snapd (2.58+20.04) ...\n",
            "Setting up apparmor (2.13.3-7ubuntu5.1) ...\n",
            "Created symlink /etc/systemd/system/sysinit.target.wants/apparmor.service → /lib/systemd/system/apparmor.service.\n",
            "Setting up liblzo2-2:amd64 (2.10-2) ...\n",
            "Setting up squashfs-tools (1:4.4-1ubuntu0.3) ...\n",
            "Setting up snapd (2.58+20.04) ...\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.aa-prompt-listener.service → /lib/systemd/system/snapd.aa-prompt-listener.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.apparmor.service → /lib/systemd/system/snapd.apparmor.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.autoimport.service → /lib/systemd/system/snapd.autoimport.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.core-fixup.service → /lib/systemd/system/snapd.core-fixup.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.recovery-chooser-trigger.service → /lib/systemd/system/snapd.recovery-chooser-trigger.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n",
            "Created symlink /etc/systemd/system/cloud-final.service.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.service → /lib/systemd/system/snapd.service.\n",
            "Created symlink /etc/systemd/system/timers.target.wants/snapd.snap-repair.timer → /lib/systemd/system/snapd.snap-repair.timer.\n",
            "Created symlink /etc/systemd/system/sockets.target.wants/snapd.socket → /lib/systemd/system/snapd.socket.\n",
            "Created symlink /etc/systemd/system/final.target.wants/snapd.system-shutdown.service → /lib/systemd/system/snapd.system-shutdown.service.\n",
            "Selecting previously unselected package chromium-browser.\n",
            "(Reading database ... 128578 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-browser_1%3a85.0.4183.83-0ubuntu0.20.04.3_amd64.deb ...\n",
            "=> Installing the chromium snap\n",
            "==> Checking connectivity with the snap store\n",
            "===> System doesn't have a working snapd, skipping\n",
            "Unpacking chromium-browser (1:85.0.4183.83-0ubuntu0.20.04.3) ...\n",
            "Setting up chromium-browser (1:85.0.4183.83-0ubuntu0.20.04.3) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "Processing triggers for systemd (245.4-4ubuntu3.20) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Processing triggers for dbus (1.12.16-2ubuntu2.3) ...\n",
            "Processing triggers for mime-support (3.64ubuntu1) ...\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "The following additional packages will be installed:\n",
            "  chromium-common chromium-sandbox libevent-2.1-6 libicu63 libimobiledevice6\n",
            "  libjpeg62-turbo libplist3 libre2-5 libu2f-udev libusbmuxd6 libvpx5\n",
            "  libxxf86dga1 upower usbmuxd x11-utils\n",
            "Suggested packages:\n",
            "  chromium-l10n chromium-shell libusbmuxd-tools mesa-utils\n",
            "The following NEW packages will be installed:\n",
            "  chromium chromium-common chromium-driver chromium-sandbox libevent-2.1-6\n",
            "  libicu63 libimobiledevice6 libjpeg62-turbo libplist3 libre2-5 libu2f-udev\n",
            "  libusbmuxd6 libvpx5 libxxf86dga1 upower usbmuxd x11-utils\n",
            "0 upgraded, 17 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 74.6 MB of archives.\n",
            "After this operation, 256 MB of additional disk space will be used.\n",
            "Get:1 http://deb.debian.org/debian buster/main amd64 libevent-2.1-6 amd64 2.1.8-stable-4 [177 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/main amd64 libre2-5 amd64 20200101+dfsg-1build1 [162 kB]\n",
            "Get:3 http://deb.debian.org/debian buster/main amd64 libicu63 amd64 63.1-6+deb10u3 [8,293 kB]\n",
            "Get:4 http://deb.debian.org/debian buster/main amd64 libjpeg62-turbo amd64 1:1.5.2-2+deb10u1 [133 kB]\n",
            "Get:5 http://deb.debian.org/debian buster/main amd64 libvpx5 amd64 1.7.0-3+deb10u1 [800 kB]\n",
            "Get:6 http://deb.debian.org/debian buster/main amd64 chromium-common amd64 90.0.4430.212-1~deb10u1 [1,423 kB]\n",
            "Get:7 http://deb.debian.org/debian buster/main amd64 chromium amd64 90.0.4430.212-1~deb10u1 [58.3 MB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu focal/main amd64 libxxf86dga1 amd64 2:1.1.5-0ubuntu1 [12.0 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu focal/main amd64 x11-utils amd64 7.7+5 [199 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu focal/main amd64 libplist3 amd64 2.1.0-4build2 [31.6 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu focal/main amd64 libusbmuxd6 amd64 2.0.1-2 [19.1 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal/main amd64 libimobiledevice6 amd64 1.2.1~git20191129.9f79242-1build1 [65.2 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu focal/main amd64 libu2f-udev all 1.1.10-1 [6,108 B]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu focal/main amd64 upower amd64 0.99.11-1build2 [104 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu focal/main amd64 usbmuxd amd64 1.1.1~git20191130.9af2b12-1 [38.4 kB]\n",
            "Get:16 http://deb.debian.org/debian buster/main amd64 chromium-driver amd64 90.0.4430.212-1~deb10u1 [4,703 kB]\n",
            "Get:17 http://deb.debian.org/debian buster/main amd64 chromium-sandbox amd64 90.0.4430.212-1~deb10u1 [146 kB]\n",
            "Fetched 74.6 MB in 1s (105 MB/s)\n",
            "Selecting previously unselected package libevent-2.1-6:amd64.\n",
            "(Reading database ... 128592 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libevent-2.1-6_2.1.8-stable-4_amd64.deb ...\n",
            "Unpacking libevent-2.1-6:amd64 (2.1.8-stable-4) ...\n",
            "Selecting previously unselected package libicu63:amd64.\n",
            "Preparing to unpack .../01-libicu63_63.1-6+deb10u3_amd64.deb ...\n",
            "Unpacking libicu63:amd64 (63.1-6+deb10u3) ...\n",
            "Selecting previously unselected package libjpeg62-turbo:amd64.\n",
            "Preparing to unpack .../02-libjpeg62-turbo_1%3a1.5.2-2+deb10u1_amd64.deb ...\n",
            "Unpacking libjpeg62-turbo:amd64 (1:1.5.2-2+deb10u1) ...\n",
            "Selecting previously unselected package libre2-5:amd64.\n",
            "Preparing to unpack .../03-libre2-5_20200101+dfsg-1build1_amd64.deb ...\n",
            "Unpacking libre2-5:amd64 (20200101+dfsg-1build1) ...\n",
            "Selecting previously unselected package libvpx5:amd64.\n",
            "Preparing to unpack .../04-libvpx5_1.7.0-3+deb10u1_amd64.deb ...\n",
            "Unpacking libvpx5:amd64 (1.7.0-3+deb10u1) ...\n",
            "Selecting previously unselected package libxxf86dga1:amd64.\n",
            "Preparing to unpack .../05-libxxf86dga1_2%3a1.1.5-0ubuntu1_amd64.deb ...\n",
            "Unpacking libxxf86dga1:amd64 (2:1.1.5-0ubuntu1) ...\n",
            "Selecting previously unselected package x11-utils.\n",
            "Preparing to unpack .../06-x11-utils_7.7+5_amd64.deb ...\n",
            "Unpacking x11-utils (7.7+5) ...\n",
            "Selecting previously unselected package chromium-common.\n",
            "Preparing to unpack .../07-chromium-common_90.0.4430.212-1~deb10u1_amd64.deb ...\n",
            "Unpacking chromium-common (90.0.4430.212-1~deb10u1) ...\n",
            "Selecting previously unselected package chromium.\n",
            "Preparing to unpack .../08-chromium_90.0.4430.212-1~deb10u1_amd64.deb ...\n",
            "Unpacking chromium (90.0.4430.212-1~deb10u1) ...\n",
            "Selecting previously unselected package chromium-driver.\n",
            "Preparing to unpack .../09-chromium-driver_90.0.4430.212-1~deb10u1_amd64.deb ...\n",
            "Unpacking chromium-driver (90.0.4430.212-1~deb10u1) ...\n",
            "Selecting previously unselected package chromium-sandbox.\n",
            "Preparing to unpack .../10-chromium-sandbox_90.0.4430.212-1~deb10u1_amd64.deb ...\n",
            "Unpacking chromium-sandbox (90.0.4430.212-1~deb10u1) ...\n",
            "Selecting previously unselected package libplist3:amd64.\n",
            "Preparing to unpack .../11-libplist3_2.1.0-4build2_amd64.deb ...\n",
            "Unpacking libplist3:amd64 (2.1.0-4build2) ...\n",
            "Selecting previously unselected package libusbmuxd6:amd64.\n",
            "Preparing to unpack .../12-libusbmuxd6_2.0.1-2_amd64.deb ...\n",
            "Unpacking libusbmuxd6:amd64 (2.0.1-2) ...\n",
            "Selecting previously unselected package libimobiledevice6:amd64.\n",
            "Preparing to unpack .../13-libimobiledevice6_1.2.1~git20191129.9f79242-1build1_amd64.deb ...\n",
            "Unpacking libimobiledevice6:amd64 (1.2.1~git20191129.9f79242-1build1) ...\n",
            "Selecting previously unselected package libu2f-udev.\n",
            "Preparing to unpack .../14-libu2f-udev_1.1.10-1_all.deb ...\n",
            "Unpacking libu2f-udev (1.1.10-1) ...\n",
            "Selecting previously unselected package upower.\n",
            "Preparing to unpack .../15-upower_0.99.11-1build2_amd64.deb ...\n",
            "Unpacking upower (0.99.11-1build2) ...\n",
            "Selecting previously unselected package usbmuxd.\n",
            "Preparing to unpack .../16-usbmuxd_1.1.1~git20191130.9af2b12-1_amd64.deb ...\n",
            "Unpacking usbmuxd (1.1.1~git20191130.9af2b12-1) ...\n",
            "Setting up libplist3:amd64 (2.1.0-4build2) ...\n",
            "Setting up libu2f-udev (1.1.10-1) ...\n",
            "Failed to send reload request: No such file or directory\n",
            "Setting up libxxf86dga1:amd64 (2:1.1.5-0ubuntu1) ...\n",
            "Setting up chromium-sandbox (90.0.4430.212-1~deb10u1) ...\n",
            "Setting up libicu63:amd64 (63.1-6+deb10u3) ...\n",
            "Setting up libjpeg62-turbo:amd64 (1:1.5.2-2+deb10u1) ...\n",
            "Setting up libevent-2.1-6:amd64 (2.1.8-stable-4) ...\n",
            "Setting up libusbmuxd6:amd64 (2.0.1-2) ...\n",
            "Setting up x11-utils (7.7+5) ...\n",
            "Setting up libre2-5:amd64 (20200101+dfsg-1build1) ...\n",
            "Setting up chromium-common (90.0.4430.212-1~deb10u1) ...\n",
            "Setting up libimobiledevice6:amd64 (1.2.1~git20191129.9f79242-1build1) ...\n",
            "Setting up libvpx5:amd64 (1.7.0-3+deb10u1) ...\n",
            "Setting up upower (0.99.11-1build2) ...\n",
            "Setting up usbmuxd (1.1.1~git20191130.9af2b12-1) ...\n",
            "Warning: The home dir /var/lib/usbmux you specified can't be accessed: No such file or directory\n",
            "Adding system user `usbmux' (UID 107) ...\n",
            "Adding new user `usbmux' (UID 107) with group `plugdev' ...\n",
            "Not creating home directory `/var/lib/usbmux'.\n",
            "Setting up chromium (90.0.4430.212-1~deb10u1) ...\n",
            "Setting up chromium-driver (90.0.4430.212-1~deb10u1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Processing triggers for dbus (1.12.16-2ubuntu2.3) ...\n",
            "Processing triggers for mime-support (3.64ubuntu1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.9/384.9 KB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.Using Selenium to load full page and BeautifulSoup to Extract information"
      ],
      "metadata": {
        "id": "UBEt_1TUMZvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Essential Libraries\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "import pandas as pd\n",
        "import os"
      ],
      "metadata": {
        "id": "StWgM_yYMXCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up Webdriver for Google Colab\n",
        "\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--disable-gpu')\n",
        "options.add_argument('--disable-dve-shm-uage')\n",
        "\n",
        "driver= webdriver.Chrome(executable_path='/usr/bin/chromedriver',options=options)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiAzT1K4Yttr",
        "outputId": "7f7ad70f-b600-41f1-fcbf-b216c4d3a3c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-5cf7f98098e2>:9: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
            "  driver= webdriver.Chrome(executable_path='/usr/bin/chromedriver',options=options)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.Writing Helper Functions"
      ],
      "metadata": {
        "id": "GLer4g6iTO_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to create CSV file \n",
        "\n",
        "def CSV_Convertor(name,input_dict):\n",
        "  CSV_df=pd.DataFrame(input_dict)\n",
        "  CSV_df.to_csv(name+'.csv',index=False)\n",
        "  return None"
      ],
      "metadata": {
        "id": "b3qotNxJTXn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to press loadmore button n number of times\n",
        "\n",
        "def press_button(driver, times):\n",
        "  \n",
        "  for i in range(times):\n",
        "    while True:\n",
        "      try:\n",
        "        # find and click \"Load More\" button\n",
        "        load_more_button = WebDriverWait(driver, 10).until(\n",
        "            EC.element_to_be_clickable((By.CLASS_NAME, 'ajax-pagination-btn')))\n",
        "        load_more_button.click()\n",
        "        time.sleep(5)\n",
        "        break\n",
        "\n",
        "      except:\n",
        "        break\n",
        "\n",
        "  return None  "
      ],
      "metadata": {
        "id": "3RL11H8SCEBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting star_counts into an integer\n",
        "\n",
        "def parse_star_count(stars_str):\n",
        "  if stars_str[-1]=='k':\n",
        "    return int(float(stars_str[:-1])*1000)\n",
        "  \n",
        "  return int(stars_str)"
      ],
      "metadata": {
        "id": "_OBfp1g-wf9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to get all topics and its corresponding info present on github/topics and save it into a dictionary\n",
        "\n",
        "def get_topics():\n",
        "  \n",
        "  driver.get('https://github.com/topics')\n",
        "\n",
        "  press_button(driver,5)\n",
        "\n",
        "  topic_name,topic_desc,topic_url=get_topic_info(BeautifulSoup(driver.page_source, \n",
        "                                                          'html.parser'))\n",
        "  \n",
        "  topic_dict={\n",
        "      'topic_name':topic_name,\n",
        "      'topic_description':topic_desc,\n",
        "      'topic_url':topic_url\n",
        "  }\n",
        "\n",
        "  return topic_dict"
      ],
      "metadata": {
        "id": "60EW2nmPrI9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to retrive info from parsed html page and return it back to 'get_topic'\n",
        "\n",
        "def get_repo_info(html_page):\n",
        "  \n",
        "  h3_class='f3 color-fg-muted text-normal lh-condensed'\n",
        "  star_class='Counter js-social-count'\n",
        "  repo_info=html_page.find_all('h3',{'class':h3_class})\n",
        "  star_info=html_page.find_all('span',{'class':star_class})\n",
        "\n",
        "  username=[]\n",
        "  repo_name=[]\n",
        "  repo_url=[]\n",
        "  star_count=[]\n",
        "\n",
        "  for i in range(len(repo_info)):\n",
        "    a_tags=repo_info[i].find_all('a')\n",
        "    username.append(a_tags[0].text.strip())\n",
        "    repo_name.append(a_tags[1].text.strip())\n",
        "    repo_url.append('https://github.com' + a_tags[1]['href'])\n",
        "    star_count.append(parse_star_count(star_info[i].text.strip()))\n",
        "    \n",
        "  return username,repo_name,star_count,repo_url"
      ],
      "metadata": {
        "id": "VRHIzMURp6tJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to get each topic webpage and save its info as a dictionary\n",
        "\n",
        "def get_topic_repos(topic_url):\n",
        "\n",
        "  driver.get(topic_url)\n",
        "\n",
        "  press_button(driver,1)\n",
        "\n",
        "  username,repo_name,star_count,repo_url=get_repo_info(BeautifulSoup(driver.page_source, \n",
        "                                                          'html.parser'))\n",
        "  info_dict={\n",
        "      'username':username,\n",
        "      'repo_name':repo_name,\n",
        "      'stars_count':star_count,\n",
        "      'repo_url':repo_url\n",
        "  }\n",
        "\n",
        "  return info_dict"
      ],
      "metadata": {
        "id": "VF8-MnKOp_S6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to retrive info from parsed html page and return it back to 'get_topic_repos'\n",
        "\n",
        "def get_topic_info(html_page):\n",
        "\n",
        "  title_class='f3 lh-condensed mb-0 mt-1 Link--primary'\n",
        "  desc_class='f5 color-fg-muted mb-0 mt-1'\n",
        "  url_class='no-underline flex-1 d-flex flex-column'\n",
        "\n",
        "  title_info=html_page.find_all('p',{'class':title_class})\n",
        "  desc_info=html_page.find_all('p',{'class':desc_class})\n",
        "  url_info=html_page.find_all('a',{'class':url_class})\n",
        "\n",
        "\n",
        "  topic_name=[]\n",
        "  topic_desc=[]\n",
        "  topic_url=[]\n",
        "\n",
        "  for i in range(len(title_info)):\n",
        "    topic_name.append(title_info[i].text.strip())\n",
        "    topic_desc.append(desc_info[i].text.strip())\n",
        "    topic_url.append('https://github.com'+url_info[i]['href'])\n",
        "\n",
        "  return topic_name,topic_desc,topic_url\n"
      ],
      "metadata": {
        "id": "jd2fRvENzA5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# button to generate all info\n",
        "\n",
        "def generate_info():\n",
        "  folder1_name = 'topic_info'\n",
        "  folder2_name = 'repo_info'\n",
        "  folder1_path = '/content/' + folder1_name\n",
        "  folder2_path=folder1_path + '/' + folder2_name\n",
        "\n",
        "  if not os.path.exists(folder1_path):\n",
        "    os.makedirs(folder1_path)\n",
        "\n",
        "  CSV_Convertor('topics',get_topics())\n",
        "  os.replace('/content/topics.csv', folder1_path+'/'+'topics.csv')\n",
        "\n",
        "  CSV_Convertor('merged_file',repo_generator())\n",
        "  os.replace('/content/merged_file.csv', folder1_path+'/'+'merged_file.csv')\n",
        "\n",
        "  return None"
      ],
      "metadata": {
        "id": "QGNiYpc8Y4O0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to make a merged dictionary and save different topics in given folders\n",
        "\n",
        "def repo_generator():\n",
        "  \n",
        "  dict_topic=[]\n",
        "  dict_username=[]\n",
        "  dict_repo_name=[]\n",
        "  dict_star_count=[]\n",
        "  dict_repo_url=[]\n",
        "  \n",
        "  if not os.path.exists('/content/topic_info/repo_info/'):\n",
        "    os.makedirs('/content/topic_info/repo_info/')\n",
        "  \n",
        "  for topic_name, topic_url in zip(get_topics()['topic_name'], get_topics()['topic_url']):\n",
        "    d=get_topic_repos(topic_url)\n",
        "    CSV_Convertor(topic_name,get_topic_repos(topic_url))\n",
        "    os.replace('/content/'+topic_name+'.csv', '/content/topic_info/repo_info/'+topic_name+'.csv')\n",
        "    for i in range(len(d['username'])):\n",
        "      dict_topic.append(topic_name)\n",
        "      dict_username.append(d['username'][i])\n",
        "      dict_repo_name.append(d['repo_name'][i])\n",
        "      dict_star_count.append(d['stars_count'][i])\n",
        "      dict_repo_url.append(d['repo_url'][i])\n",
        "\n",
        "  merged_dict={\n",
        "      'topic':dict_topic,\n",
        "      'username':dict_username,\n",
        "      'repo_name':dict_repo_name,\n",
        "      'star_count':dict_star_count,\n",
        "      'repo_url':dict_repo_url\n",
        "  }\n",
        "\n",
        "  return merged_dict"
      ],
      "metadata": {
        "id": "m8Df93sigetM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.Just Click The Button"
      ],
      "metadata": {
        "id": "GYztMbClBkzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate_info()"
      ],
      "metadata": {
        "id": "QSXvUbOVZXzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.Closing the driver and its associated window "
      ],
      "metadata": {
        "id": "BvsXlsTn_KNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "driver.quit()"
      ],
      "metadata": {
        "id": "OlRhcHRS7c5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.Common Problems and rough notebook"
      ],
      "metadata": {
        "id": "fzIGW4_v_cNU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Error message: \"Unknown error: no Chrome binary found at C:\\Program Files\\Google\\Chrome\\Application\\chrome. xe.\"**\n",
        "\n",
        "- Solution: You cannot simply call \"driver = webdriver.Chrome()\" because we are using Google Colab instead of a local IDE. To resolve this issue, you need to download the Chromium browser and its corresponding webdriver for the Google instance by executing the following commands:\n",
        "\n",
        "  apt-get update  \n",
        "  apt-get install -y chromium-browser --quiet  \n",
        "  apt-get install chromium chromium-driver --quiet\n",
        "___\n",
        "\n",
        "2. **Error message : HTTPConnectionPool(host='localhost', port=46371): Max retries exceeded with url: /session/efd08405139d53f9d9d5731b446f7b65/url (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f8be84e7640>: Failed to establish a new connection: [Errno 111] Connection refused'))**\n",
        "- Solution:This error message indicates that there was a problem establishing a connection to the specified host and port. This could occur if you attempted to access a URL using the webdriver, but the driver was not set up correctly using the webdriver.Chrome() method. Alternatively, it could be caused if you attempted to call the driver after it was already quit. To resolve this issue, make sure to properly set up the webdriver before attempting to use it and avoid trying to call it again after it has already been quit.\n",
        "___\n",
        "\n",
        "3. **Error message:WebDriverException: unknown error: cannot find Chrome binary error with Selenium in Python for older versions of Google Chrome**\n",
        "- solution: This error message suggests that there is a problem with the Chrome binary version when using Selenium with Python for older versions of Google Chrome. The pre-installed Chromium browser that can be accessed through the path /usr/lib/chromium-browser is of version 90.0, but we need a Chromium browser version 111 or higher to work with our Chromium driver.To resolve this issue, we can download the latest version of Chromium browser that is compatible with our current Chrome driver version. Then, we need to use the executable path '/usr/bin/chromedriver' to access our latest downloaded Chromium browser. By doing so, we can ensure that our Python code can interact with the latest version of the Chromium browser, and the error should be resolved.\n",
        "___\n",
        "\n",
        "4. **Different webdriver.chrome() option's and their purpose**\n",
        "- **options.add_argument('--no-sandbox')**: The sandbox mode is a security feature in Chrome that isolates web page rendering and execution in a separate process to prevent malicious web pages from accessing system files and other sensitive data.\n",
        "- **options.add_argument('--headless')**: It is used in Selenium WebDriver to run the Chrome browser in headless mode.In headless mode, the browser runs without a graphical user interface, meaning that it operates entirely in the background without displaying any windows or user interface elements. This can be beneficial in automated testing scenarios since it can speed up the test execution and reduce the resources required to run the test.\n",
        "- **options.add_argument('--disable-gpu')**: When the disable-gpu argument is passed to the options, Chrome will not use the GPU for rendering web pages, which can be useful in cases where there are compatibility issues between the browser and the GPU or when the system does not have a dedicated GPU.\n",
        "- **options.add_argument('--disable-dve-shm-uage')**:\"disable-dve-shm-usage\" is used to turn off a setting in the browser that controls how it uses shared memory when encoding video. This can help improve compatibility and security in certain situations.\n",
        "___\n",
        "5. **Error message: TimeoutException: Message: Stacktrace:#0**  \n",
        "- solution: This error message indicates a TimeoutException, and it can occur for two reasons. Firstly, it may be because the topic_url passed to the 'get_topic_repos' function is not found. This can happen when the C++ URL cannot be generated using the base_url and topic_name. Secondly, it may occur when the \"load more\" button is not found. For instance, in the case of 'WordPlate', there are only 12 repositories, so there is no load more button.\n",
        "To resolve this issue, we need to use a try-except block in our while loop. This ensures that if the error occurs due to either of the above reasons, the loop will continue to execute instead of terminating the program. By doing this, we can successfully retrieve the required data without encountering the TimeoutException error.\n",
        "___\n",
        "6. **Error:Not able to get all repositores even though loadmore button was pressed**  \n",
        "- solution:This error occurs when we are unable to retrieve all repositories even though the \"load more\" button was pressed. The reason for this is that we do not give enough time for the data to load before reading it through the driver.get() method.To resolve this issue, we need to include a pause using the time.sleep() method to give the web page enough time to load all the required data. By doing so, we can ensure that all the repositories are loaded before we attempt to retrieve them, and the error should be resolved.\n",
        "___"
      ],
      "metadata": {
        "id": "etWE0ZlybjOy"
      }
    }
  ]
}